{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Get Started with the Model\n",
    "We floows the steps on the HuggingFace webpage for the [Florence-2](https://huggingface.co/microsoft/Florence-2-large-ft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instal libraries if needed with pip -----------------------------------------#\n",
    "%pip install requests\n",
    "%pip install pillow\n",
    "%pip install transformers\n",
    "%pip install wheel\n",
    "%pip install flash_attn \n",
    "%pip install timm \n",
    "%pip install einops\n",
    "\n",
    "# load libraries --------------------------------------------------------------#\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "import torch\n",
    "print(torch.rand(3))\n",
    "\n",
    "# Check whether cuda is available for faster processing -----------------------#\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OD>': {'bboxes': [[34.23999786376953, 160.0800018310547, 597.4400024414062, 371.7599792480469], [454.7200012207031, 97.19999694824219, 579.5199584960938, 261.3599853515625], [452.79998779296875, 276.7200012207031, 553.9199829101562, 370.79998779296875], [94.4000015258789, 280.55999755859375, 196.1599884033203, 371.2799987792969]], 'labels': ['car', 'door', 'wheel', 'wheel']}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large-ft\", trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large-ft\", trust_remote_code=True)\n",
    "\n",
    "prompt = \"<OD>\"\n",
    "\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg?download=true\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    pixel_values=inputs[\"pixel_values\"],\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=False,\n",
    "    num_beams=3\n",
    ")\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "\n",
    "parsed_answer = processor.post_process_generation(generated_text, task=\"<OD>\", image_size=(image.width, image.height))\n",
    "\n",
    "print(parsed_answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
